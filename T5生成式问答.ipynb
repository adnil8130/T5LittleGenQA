{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12NvBPm1DDB9sqWlDCEC6WOvfpGljDozn",
      "authorship_tag": "ABX9TyNZIgykGPeQyJNVIeERXOOK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76583e9081d64750b7b00ecde2070d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cc1ef293ea14d2cb522c4e6e5ee468e",
              "IPY_MODEL_797edb6abd5942c69d7c5fdcc010ecfe",
              "IPY_MODEL_0e848dd1f6564f3c90a20a16f34fecd8"
            ],
            "layout": "IPY_MODEL_2285233828964112a5e913d981a84934"
          }
        },
        "4cc1ef293ea14d2cb522c4e6e5ee468e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d7b05a9a6db47e183264a8a57035e60",
            "placeholder": "​",
            "style": "IPY_MODEL_1da5d11b3e6844078baf743b04774070",
            "value": "loss: 5.033199: 100%"
          }
        },
        "797edb6abd5942c69d7c5fdcc010ecfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31d00299ca1d4e1084d913e1ff6f224f",
            "max": 1634,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91c32ced0f9d4e358bfef4e9512cad3b",
            "value": 1634
          }
        },
        "0e848dd1f6564f3c90a20a16f34fecd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8c82ee84e2498cb45d93215c6cb4ad",
            "placeholder": "​",
            "style": "IPY_MODEL_ea80814288c54e918bced19a1fee018a",
            "value": " 1634/1634 [13:00&lt;00:00,  2.41it/s]"
          }
        },
        "2285233828964112a5e913d981a84934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7b05a9a6db47e183264a8a57035e60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da5d11b3e6844078baf743b04774070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31d00299ca1d4e1084d913e1ff6f224f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c32ced0f9d4e358bfef4e9512cad3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc8c82ee84e2498cb45d93215c6cb4ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea80814288c54e918bced19a1fee018a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56aa81214b844520bfb7fd8d9d55f470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6313e8ded9cc4ecda8523c5e690222ef",
              "IPY_MODEL_7023dda94707436e869edf30535059f9",
              "IPY_MODEL_87dbd547ad4f4b06a152886bec8db31b"
            ],
            "layout": "IPY_MODEL_e4c99df5bdfd4938b9fae304e490a4dd"
          }
        },
        "6313e8ded9cc4ecda8523c5e690222ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a39a22a5da444429868b5fbdca0c0a0a",
            "placeholder": "​",
            "style": "IPY_MODEL_fa5ce883ee7448e28cb20630af65ce27",
            "value": " 91%"
          }
        },
        "7023dda94707436e869edf30535059f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6748f1f84d0c46378c67361a8f2bef90",
            "max": 182,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e3e60131f554367add77b5d6d419169",
            "value": 166
          }
        },
        "87dbd547ad4f4b06a152886bec8db31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f31a67f52644829ae4bbbc77e33a19",
            "placeholder": "​",
            "style": "IPY_MODEL_9c2c047898b54ff6a03fef58e9c17fb5",
            "value": " 166/182 [14:43&lt;01:24,  5.25s/it]"
          }
        },
        "e4c99df5bdfd4938b9fae304e490a4dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a39a22a5da444429868b5fbdca0c0a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5ce883ee7448e28cb20630af65ce27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6748f1f84d0c46378c67361a8f2bef90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e3e60131f554367add77b5d6d419169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60f31a67f52644829ae4bbbc77e33a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c2c047898b54ff6a03fef58e9c17fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnil8130/T5LittleGenQA/blob/main/T5%E7%94%9F%E6%88%90%E5%BC%8F%E9%97%AE%E7%AD%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 目标\n",
        "训练一个生成式问答模型，base模型采用Google T5-Base(\"uer/t5-base-chinese-cluecorpussmall\")\n",
        "\n",
        "预训练模型地址：https://huggingface.co/uer/t5-base-chinese-cluecorpussmall\n",
        "\n",
        "模型的评价指标采用BLEU-1，BLEU-2，BLEU-3，BLEU-4。"
      ],
      "metadata": {
        "id": "XB0rQXT6RK7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dJQKxYENR7ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据集\n",
        "数据集：链接：https://pan.quark.cn/s/6d4a98cd65f2    \n",
        "\n",
        "提取码：bzne\n",
        "\n",
        "数据的格式如下：\n",
        "```\n",
        "{\"context\": \"违规分为:一般违规扣分、严重违规扣分、出售假冒商品违规扣分,淘宝网每年12月31日24:00点会对符合条件的扣分做清零处理,详情如下:|温馨提醒:由于出售假冒商品24≤N<48分,当年的24分不清零,所以会存在第一年和第二年的不同计分情况。\", \"answer\": \"12月31日24:00\", \"question\": \"淘宝扣分什么时候清零\", \"id\": 203}\n",
        "```"
      ],
      "metadata": {
        "id": "9-mM3YxoRqpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 准备数据"
      ],
      "metadata": {
        "id": "elmV_poiR3ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import numpy as np\n",
        "import torch\n",
        "print(transformers.__version__)\n",
        "print(torch.__version__)\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import json"
      ],
      "metadata": {
        "id": "GQKExfTQ5uJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c239a73-150a-4fe7-cc8d-3577201578a1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.48.3\n",
            "2.5.1+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_context_len = 0\n",
        "max_question_len = 0\n",
        "max_answer_len = 0\n",
        "context = \"\"\n",
        "questiont = \"\"\n",
        "answer = \"\"\n",
        "\n",
        "save_path_file = '/content/drive/MyDrive'\n",
        "train_data_address = save_path_file + '/train.json'\n",
        "dev_data_address = save_path_file + '/dev.json'\n",
        "\n",
        "with open(train_data_address, 'rt', encoding='utf-8') as f:\n",
        "  for idx, line in enumerate(f):\n",
        "    sample = json.loads(line.strip())\n",
        "    if len(sample[\"context\"]) > max_question_len:\n",
        "        max_context_len = len(sample[\"context\"])\n",
        "        context = sample[\"context\"]\n",
        "    if len(sample[\"question\"]) > max_question_len:\n",
        "        max_question_len = len(sample[\"question\"])\n",
        "        question = sample[\"question\"]\n",
        "    if len(sample[\"answer\"]) > max_answer_len:\n",
        "        max_answer_len = len(sample[\"answer\"])\n",
        "        answer = sample[\"answer\"]\n",
        "\n",
        "with open(dev_data_address, 'rt', encoding='utf-8') as f:\n",
        "  for idx, line in enumerate(f):\n",
        "    sample = json.loads(line.strip())\n",
        "    if len(sample[\"context\"]) > max_question_len:\n",
        "        max_context_len = len(sample[\"context\"])\n",
        "        context = sample[\"context\"]\n",
        "    if len(sample[\"question\"]) > max_question_len:\n",
        "        max_question_len = len(sample[\"question\"])\n",
        "        question = sample[\"question\"]\n",
        "    if len(sample[\"answer\"]) > max_answer_len:\n",
        "        max_answer_len = len(sample[\"answer\"])\n",
        "        answer = sample[\"answer\"]\n",
        "\n",
        "print(\"最长context\", max_context_len, context)\n",
        "print(\"最长question\", max_question_len, question)\n",
        "print(\"最长answer\", max_answer_len, answer)"
      ],
      "metadata": {
        "id": "o1EUw3OTY-vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee181c7-18e8-4fad-a58d-898c34ed4c7f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "最长context 107 2015下半年教师资格证考试时间为11月1日，考生可于2015年10月26日—10月31日登录报名系统，根据提示下载pdf准考证文件。下载后，仔细核对个人信息，并直接打印成准考，按准考证上的要求到指定地点参加考试。\n",
            "最长question 42 痞子猪身上是什么字母? (问题由猫小逗提供)【答题格式为da+答案,例如答案是爱消除\n",
            "最长answer 110 如果下雨的时候你拖着行李箱子站在屋檐下面那么其实我没有足够的时间找一个好一点的理由抛弃家里面的狗坐上K667次列车到你在的地方找个商店买一把伞然后给我妹妹弹吉他因为她要参加比赛所以我回不去了我也不会给你说我泡面的碗还没洗\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 构建数据集"
      ],
      "metadata": {
        "id": "BUS6E7I3STnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.9\n",
        "max_dataset_size = 22000\n",
        "train_set_size = 20000\n",
        "valid_set_size = 2000\n",
        "\n",
        "class GenQA(Dataset):\n",
        "  def __init__(self, data_file):\n",
        "    self.data = self.load_data(data_file)\n",
        "\n",
        "  def load_data(self, data_file):\n",
        "    Data = {}\n",
        "    with open(data_file, 'rt', encoding='utf-8') as f:\n",
        "      for idx, line in enumerate(f):\n",
        "        if idx >= max_dataset_size:\n",
        "            break\n",
        "        sample = json.loads(line.strip())\n",
        "        Data[idx] = sample\n",
        "    return Data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]\n",
        "\n",
        "data = GenQA(train_data_address)\n",
        "data_size = len(data)\n",
        "\n",
        "train_size = int(train_ratio * data_size)\n",
        "valid_size = data_size - train_size\n",
        "train_data, valid_data = random_split(data, [train_size, valid_size])\n",
        "test_data = GenQA(dev_data_address)"
      ],
      "metadata": {
        "id": "Z8ogSFxcSKWm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train set size: {len(train_data)}')\n",
        "print(f'valid set size: {len(valid_data)}')\n",
        "print(f'test set size: {len(test_data)}')\n",
        "print(next(iter(train_data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo_XnYqUSxi4",
        "outputId": "1e6d8fb6-b07d-48b2-953a-03be15a9f143"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set size: 13068\n",
            "valid set size: 1452\n",
            "test set size: 984\n",
            "{'context': '病情分析：你好，你说这种情况的话，如果手术成功过以后具体多长时间会来月经，这个事不太好说的。一般情况下来说，一到两个月之内会来月经了。正常情况下来说，我们建议你宫腔镜手术过以后一般情况下来说，建议你选择半年以后再选择备孕，可能会更好一些。', 'answer': '一到两个月', 'question': '子宫内膜息肉术后多久来月经', 'id': 14176}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据预处理"
      ],
      "metadata": {
        "id": "jnqpVHVbU8NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "model_checkpoint = 'uer/t5-base-chinese-cluecorpussmall'\n",
        "# model_checkpoint = 'uer/t5-small-chinese-cluecorpussmall'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,return_token_type_ids=False)"
      ],
      "metadata": {
        "id": "Le1FG7QBU-O0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = train_data[0][\"context\"]\n",
        "question = train_data[0][\"question\"]\n",
        "answer = train_data[0][\"answer\"]\n",
        "\n",
        "inputs = tokenizer(context, question)\n",
        "targets = tokenizer(answer)"
      ],
      "metadata": {
        "id": "GY1qyko-VQKd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"]))\n",
        "print(tokenizer.convert_ids_to_tokens(targets[\"input_ids\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caY0L8I9Vies",
        "outputId": "8a9f32c6-e1de-4761-be04-99c87f00242f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '病', '情', '分', '析', '：', '你', '好', '，', '你', '说', '这', '种', '情', '况', '的', '话', '，', '如', '果', '手', '术', '成', '功', '过', '以', '后', '具', '体', '多', '长', '时', '间', '会', '来', '月', '经', '，', '这', '个', '事', '不', '太', '好', '说', '的', '。', '一', '般', '情', '况', '下', '来', '说', '，', '一', '到', '两', '个', '月', '之', '内', '会', '来', '月', '经', '了', '。', '正', '常', '情', '况', '下', '来', '说', '，', '我', '们', '建', '议', '你', '宫', '腔', '镜', '手', '术', '过', '以', '后', '一', '般', '情', '况', '下', '来', '说', '，', '建', '议', '你', '选', '择', '半', '年', '以', '后', '再', '选', '择', '备', '孕', '，', '可', '能', '会', '更', '好', '一', '些', '。', '[SEP]', '子', '宫', '内', '膜', '息', '肉', '术', '后', '多', '久', '来', '月', '经', '[SEP]']\n",
            "['[CLS]', '一', '到', '两', '个', '月', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "max_input_length = 256\n",
        "max_target_length = 256\n",
        "sample_cnt = 4\n",
        "\n",
        "inputs = [train_data[s_idx][\"context\"] + train_data[s_idx][\"question\"] for s_idx in range(sample_cnt)]\n",
        "targets = [train_data[s_idx][\"answer\"] for s_idx in range(sample_cnt)]\n",
        "\n",
        "model_inputs = tokenizer(\n",
        "    inputs,\n",
        "    padding=True,\n",
        "    max_length=max_input_length,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "labels = tokenizer(\n",
        "    text_target=targets,\n",
        "    padding=True,\n",
        "    max_length=max_target_length,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",\n",
        "    return_token_type_ids=False\n",
        ")[\"input_ids\"]\n",
        "\n",
        "end_token_index = torch.where(labels == 102)[-1]\n",
        "for idx, end_idx in enumerate(end_token_index):\n",
        "    labels[idx][end_idx+1:] = -100\n",
        "\n",
        "print('batch_X shape:', {k: v.shape for k, v in model_inputs.items()})\n",
        "print('batch_y shape:', labels.shape)\n",
        "print(model_inputs)\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MjjjsKUBVu36",
        "outputId": "1b308075-fead-4872-ec5f-69d5aecbe8da"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_X shape: {'input_ids': torch.Size([4, 256]), 'attention_mask': torch.Size([4, 256])}\n",
            "batch_y shape: torch.Size([4, 7])\n",
            "{'input_ids': tensor([[ 101, 4567, 2658,  ...,    0,    0,    0],\n",
            "        [ 101,  122,  510,  ..., 4638,  511,  102],\n",
            "        [ 101, 4680, 1184,  ...,    0,    0,    0],\n",
            "        [ 101, 1184, 7028,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
            "tensor([[ 101,  671, 1168,  697,  702, 3299,  102],\n",
            "        [ 101,  100,  102, -100, -100, -100, -100],\n",
            "        [ 101, 8769, 2340, 1381,  102, -100, -100],\n",
            "        [ 101, 3187, 3309, 2530, 1152,  102, -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XBitfLngKwq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "import gc\n",
        "\n",
        "\n",
        "max_length = 256\n",
        "train_batch_size = 8\n",
        "test_batch_size = 64\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "def clean_cuda(device):\n",
        "    if device == 'cuda':\n",
        "        # 清理无用变量\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # 查看清理后剩余显存\n",
        "        print(f\"释放后可用显存: {torch.cuda.mem_get_info()[0]/1024**3:.2f} GB\")\n",
        "\n",
        "clean_cuda(device)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "model = model.to(device)\n",
        "\n",
        "def collote_fn(batch_samples):\n",
        "    batch_inputs, batch_targets = [], []\n",
        "    for sample in batch_samples:\n",
        "        batch_inputs.append(sample[\"context\"] + sample[\"question\"])\n",
        "        batch_targets.append(sample['answer'])\n",
        "    batch_data = tokenizer(\n",
        "        batch_inputs,\n",
        "        text_target=batch_targets,\n",
        "        padding=True,\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "        return_token_type_ids=False\n",
        "    )\n",
        "    batch_data['decoder_input_ids'] = model.prepare_decoder_input_ids_from_labels(batch_data['labels'])\n",
        "    end_token_index = torch.where(batch_data['labels'] == 102)[-1]\n",
        "    for idx, end_idx in enumerate(end_token_index):\n",
        "        batch_data['labels'][idx][end_idx+1:] = -100\n",
        "    return batch_data\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True, collate_fn=collote_fn)\n",
        "valid_dataloader = DataLoader(valid_data, batch_size=test_batch_size, shuffle=False, collate_fn=collote_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WBkuH4sdMOq",
        "outputId": "78c68444-eb57-4a62-c2c6-323083ee0fd7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "print(batch.keys())\n",
        "print('batch shape:', {k: v.shape for k, v in batch.items()})\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR9ghtPidvfn",
        "outputId": "2dea3d13-eb64-48f1-c067-55bc9e81ae7e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])\n",
            "batch shape: {'input_ids': torch.Size([8, 256]), 'attention_mask': torch.Size([8, 256]), 'labels': torch.Size([8, 12]), 'decoder_input_ids': torch.Size([8, 12])}\n",
            "{'input_ids': tensor([[ 101, 3297, 3326,  ...,    0,    0,    0],\n",
            "        [ 101,  677,  702,  ...,    0,    0,    0],\n",
            "        [ 101, 7227, 1762,  ..., 1400, 8024,  102],\n",
            "        ...,\n",
            "        [ 101, 1071, 2141,  ..., 2347, 5307,  102],\n",
            "        [ 101,  122,  510,  ...,    0,    0,    0],\n",
            "        [ 101,  517, 3617,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[  101,   782,  3696,  1139,  4276,  4852,   102,  -100,  -100,  -100,\n",
            "          -100,  -100],\n",
            "        [  101,   122,   119,   124,  1039,   782,  3696,  2355,   102,  -100,\n",
            "          -100,  -100],\n",
            "        [  101, 13055,   119,  8251,  8320,   102,  -100,  -100,  -100,  -100,\n",
            "          -100,  -100],\n",
            "        [  101,  8195,  1914,   102,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "          -100,  -100],\n",
            "        [  101,  5558,  5968,   671,  3613,  1112,   102,  -100,  -100,  -100,\n",
            "          -100,  -100],\n",
            "        [  101,   124,   702,  3299,   102,  -100,  -100,  -100,  -100,  -100,\n",
            "          -100,  -100],\n",
            "        [  101,  1357,  2533,  4925,  1218,  4633,  6381,  6395,  4638,  3613,\n",
            "          3299,   102],\n",
            "        [  101,  3617,  3307,   722,  6117,   125,   102,  -100,  -100,  -100,\n",
            "          -100,  -100]]), 'decoder_input_ids': tensor([[  101,   101,   782,  3696,  1139,  4276,  4852,   102,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,   101,   122,   119,   124,  1039,   782,  3696,  2355,   102,\n",
            "             0,     0],\n",
            "        [  101,   101, 13055,   119,  8251,  8320,   102,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,   101,  8195,  1914,   102,     0,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,   101,  5558,  5968,   671,  3613,  1112,   102,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,   101,   124,   702,  3299,   102,     0,     0,     0,     0,\n",
            "             0,     0],\n",
            "        [  101,   101,  1357,  2533,  4925,  1218,  4633,  6381,  6395,  4638,\n",
            "          3613,  3299],\n",
            "        [  101,   101,  3617,  3307,   722,  6117,   125,   102,     0,     0,\n",
            "             0,     0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 模型训练"
      ],
      "metadata": {
        "id": "VJdOb5nxesPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 优化模型参数"
      ],
      "metadata": {
        "id": "ZHyz8nghijIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "\n",
        "def train_loop(dataloader, model, optimizer, lr_scheduler, epoch, total_loss, sample_ovserve_ratio=0.01):\n",
        "    progress_bar = tqdm(range(len(dataloader)))\n",
        "    progress_bar.set_description(f'loss: {0:>7f}')\n",
        "    finish_batch_num = (epoch-1) * len(dataloader)\n",
        "\n",
        "    model.train()\n",
        "    loss_record_step = []\n",
        "    for batch, batch_data in enumerate(dataloader, start=1):\n",
        "        batch_data = batch_data.to(device)\n",
        "        outputs = model(**batch_data)\n",
        "\n",
        "        random_number = random.uniform(0, 1)\n",
        "        if random_number < sample_ovserve_ratio:\n",
        "            print(\"input:\", tokenizer.batch_decode(batch_data[\"input_ids\"].cpu().numpy(), skip_special_tokens=True))\n",
        "            print(\"output:\", outputs)\n",
        "\n",
        "\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        loss_record_step.append(loss.item())\n",
        "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
        "        progress_bar.update(1)\n",
        "    return total_loss, loss_record_step"
      ],
      "metadata": {
        "id": "CRDgt2jwey54"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 评估指标"
      ],
      "metadata": {
        "id": "ehnFChOsio3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sacrebleu"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LpRNVcWRfiEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fae9a1-91c1-4022-b213-302123906801"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sacrebleu.metrics import BLEU\n",
        "\n",
        "predictions = [\n",
        "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
        "]\n",
        "bad_predictions_1 = [\"This This This This\"]\n",
        "bad_predictions_2 = [\"This plugin\"]\n",
        "references = [\n",
        "    [\n",
        "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
        "    ]\n",
        "]\n",
        "\n",
        "bleu1 = BLEU(max_ngram_order=1)\n",
        "print(\"==========BLEU-1==========\")\n",
        "print(bleu1.corpus_score(predictions, references).score)\n",
        "print(bleu1.corpus_score(bad_predictions_1, references).score)\n",
        "print(bleu1.corpus_score(bad_predictions_2, references).score)\n",
        "\n",
        "bleu2 = BLEU(max_ngram_order=2)\n",
        "print(\"==========BLEU-2==========\")\n",
        "print(bleu2.corpus_score(predictions, references).score)\n",
        "print(bleu2.corpus_score(bad_predictions_1, references).score)\n",
        "print(bleu2.corpus_score(bad_predictions_2, references).score)\n",
        "\n",
        "bleu3 = BLEU(max_ngram_order=3)\n",
        "print(\"==========BLEU-3==========\")\n",
        "print(bleu3.corpus_score(predictions, references).score)\n",
        "print(bleu3.corpus_score(bad_predictions_1, references).score)\n",
        "print(bleu3.corpus_score(bad_predictions_2, references).score)\n",
        "\n",
        "bleu4 = BLEU(max_ngram_order=4)\n",
        "print(\"==========BLEU-4==========\")\n",
        "print(bleu4.corpus_score(predictions, references).score)\n",
        "print(bleu4.corpus_score(bad_predictions_1, references).score)\n",
        "print(bleu4.corpus_score(bad_predictions_2, references).score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB3M-Slvffim",
        "outputId": "beeb5cfd-a6a8-4c1f-a14a-61ce9265a1ed"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========BLEU-1==========\n",
            "84.33740467435464\n",
            "2.634980614046608\n",
            "0.40867714384640685\n",
            "==========BLEU-2==========\n",
            "65.05696445772017\n",
            "2.1514526621798953\n",
            "0.40867714384640685\n",
            "==========BLEU-3==========\n",
            "53.804523766396244\n",
            "1.8269935164445736\n",
            "0.0\n",
            "==========BLEU-4==========\n",
            "46.750469682990165\n",
            "1.683602693167689\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def test_loop(dataloader, model, sample_ovserve_ratio=0.05):\n",
        "    preds, labels = [], []\n",
        "\n",
        "    model.eval()\n",
        "    for batch_data in tqdm(dataloader):\n",
        "        batch_data = batch_data.to(device)\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(\n",
        "                batch_data[\"input_ids\"],\n",
        "                attention_mask=batch_data[\"attention_mask\"],\n",
        "                max_length=max_length,\n",
        "            ).cpu().numpy()\n",
        "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
        "\n",
        "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "        random_number = random.uniform(0, 1)\n",
        "        if random_number < sample_ovserve_ratio:\n",
        "            print(\"input:\", tokenizer.batch_decode(batch_data[\"input_ids\"].cpu().numpy(), skip_special_tokens=True))\n",
        "            print(\"output:\", decoded_preds)\n",
        "\n",
        "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
        "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
        "\n",
        "        preds += [pred.strip() for pred in decoded_preds]\n",
        "        labels += [[label.strip()] for label in decoded_labels]\n",
        "    return bleu1.corpus_score(preds, labels).score, bleu2.corpus_score(preds, labels).score, bleu3.corpus_score(preds, labels).score, bleu4.corpus_score(preds, labels).score"
      ],
      "metadata": {
        "id": "VxlqEdXEhvlq"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 保存模型"
      ],
      "metadata": {
        "id": "L46eosJXsuju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data = GenQA(dev_data_address)\n",
        "# test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collote_fn)\n",
        "\n",
        "# test_loop(test_dataloader, model)"
      ],
      "metadata": {
        "id": "gI25jCsQwp7w"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def save_data_and_plot(data, txt_file_path, img_file_path):\n",
        "    # ===================== 写入文件部分 =====================\n",
        "    # 追加写入数据（自动创建文件）\n",
        "    with open(txt_file_path, 'a') as f:\n",
        "        # 将数字转为字符串并换行写入\n",
        "        f.write('\\n'.join(map(str, original_data)))\n",
        "        f.write('\\n')  # 添加换行符分隔不同写入批次\n",
        "\n",
        "    # ===================== 读取文件部分 =====================\n",
        "    # 从文件读取所有数字\n",
        "    loaded_data = []\n",
        "    try:\n",
        "        with open(txt_file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                # 去除空白字符并尝试转换为浮点数\n",
        "                cleaned_line = line.strip()\n",
        "                if cleaned_line:\n",
        "                    loaded_data.append(float(cleaned_line))\n",
        "    except FileNotFoundError:\n",
        "        print(\"错误：文件不存在\")\n",
        "        exit()\n",
        "\n",
        "    # ===================== 绘图部分 =====================\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(loaded_data,\n",
        "            color='green',\n",
        "            linestyle='--',\n",
        "            marker='s',\n",
        "            markersize=8,\n",
        "            linewidth=2)\n",
        "\n",
        "    # 图表装饰\n",
        "    plt.title(\"数值变化曲线\", fontsize=14, pad=20)\n",
        "    plt.xlabel(\"数据索引\", fontsize=12, labelpad=10)\n",
        "    plt.ylabel(\"测量值\", fontsize=12, labelpad=10)\n",
        "    plt.grid(True, alpha=0.4, linestyle=':')\n",
        "\n",
        "    # 自动调整坐标轴范围\n",
        "    plt.xlim(0, len(loaded_data)-1)\n",
        "    plt.ylim(min(loaded_data)-1, max(loaded_data)+1)\n",
        "\n",
        "    # 保存和显示\n",
        "    plt.savefig(img_file_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()  # 关闭图表释放内存\n",
        "\n",
        "    print(\"操作结果：\")\n",
        "    print(f\"- 数据已保存至 {txt_file_path}\")\n",
        "    print(f\"- 生成曲线图：{img_file_path}\")\n",
        "    print(f\"- 加载数据量：{len(loaded_data)} 条\")"
      ],
      "metadata": {
        "id": "byUCeeMq3r7v"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_scheduler\n",
        "\n",
        "learning_rate = 2e-5\n",
        "epoch_num = 50\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=epoch_num*len(train_dataloader),\n",
        ")\n",
        "\n",
        "total_loss = 0.\n",
        "best_bleu1 = 0.\n",
        "best_bleu2 = 0.\n",
        "best_bleu3 = 0.\n",
        "best_bleu4 = 0.\n",
        "best_bleu_weighted_add = 0.\n",
        "txt_file_path = save_path_file + '/lossdata.txt'\n",
        "img_file_path = save_path_file + '/lossdata.png'\n",
        "model_parm_path = None\n",
        "\n",
        "if model_parm_path is not None:\n",
        "    model.load_state_dict(torch.load(model_parm_path))\n",
        "\n",
        "for t in range(epoch_num):\n",
        "    clean_cuda(device)\n",
        "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
        "\n",
        "    total_loss, loss_record_step = train_loop(train_dataloader, model, optimizer, lr_scheduler, t+1, total_loss)\n",
        "    save_data_and_plot(loss_record_step, txt_file_path, img_file_path)\n",
        "    clean_cuda(device)\n",
        "    valid_bleu1, valid_bleu2, valid_bleu3, valid_bleu4 = test_loop(valid_dataloader, model)\n",
        "    print(f\"BLEU1: {valid_bleu1:>0.2f}\\n\")\n",
        "    if valid_bleu1 > best_bleu1:\n",
        "        best_bleu1 = valid_bleu1\n",
        "    print(f\"BLEU2: {valid_bleu2:>0.2f}\\n\")\n",
        "    if valid_bleu2 > best_bleu2:\n",
        "        best_bleu2 = valid_bleu2\n",
        "    print(f\"BLEU3: {valid_bleu3:>0.2f}\\n\")\n",
        "    if valid_bleu3 > best_bleu3:\n",
        "        best_bleu3 = valid_bleu3\n",
        "    print(f\"BLEU4: {valid_bleu4:>0.2f}\\n\")\n",
        "    if valid_bleu4 > best_bleu4:\n",
        "        best_bleu4 = valid_bleu4\n",
        "\n",
        "    valid_bleu = 0.1 * valid_bleu1 + 0.2 * valid_bleu2 + 0.3 * valid_bleu3 + 0.4 * valid_bleu4\n",
        "    if valid_bleu > best_bleu_weighted_add or epoch_num % 2 == 0:\n",
        "        best_bleu_weighted_add = valid_bleu\n",
        "        print('saving new weights...\\n')\n",
        "        torch.save(model.state_dict(), save_path_file + f'/epoch_{t+1}_loss_{loss_record_step[-1]:0.7f}_valid_bleu_{valid_bleu:0.2f}_model_weights.bin')\n",
        "    clean_cuda(device)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "76583e9081d64750b7b00ecde2070d03",
            "4cc1ef293ea14d2cb522c4e6e5ee468e",
            "797edb6abd5942c69d7c5fdcc010ecfe",
            "0e848dd1f6564f3c90a20a16f34fecd8",
            "2285233828964112a5e913d981a84934",
            "0d7b05a9a6db47e183264a8a57035e60",
            "1da5d11b3e6844078baf743b04774070",
            "31d00299ca1d4e1084d913e1ff6f224f",
            "91c32ced0f9d4e358bfef4e9512cad3b",
            "dc8c82ee84e2498cb45d93215c6cb4ad",
            "ea80814288c54e918bced19a1fee018a",
            "56aa81214b844520bfb7fd8d9d55f470",
            "6313e8ded9cc4ecda8523c5e690222ef",
            "7023dda94707436e869edf30535059f9",
            "87dbd547ad4f4b06a152886bec8db31b",
            "e4c99df5bdfd4938b9fae304e490a4dd",
            "a39a22a5da444429868b5fbdca0c0a0a",
            "fa5ce883ee7448e28cb20630af65ce27",
            "6748f1f84d0c46378c67361a8f2bef90",
            "4e3e60131f554367add77b5d6d419169",
            "60f31a67f52644829ae4bbbc77e33a19",
            "9c2c047898b54ff6a03fef58e9c17fb5"
          ]
        },
        "id": "2UZZUYopsts1",
        "outputId": "05231a38-6d89-4716-e252-50725bbd572b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "释放后可用显存: 8.85 GB\n",
            "Epoch 1/50\n",
            "-------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1634 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76583e9081d64750b7b00ecde2070d03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/182 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56aa81214b844520bfb7fd8d9d55f470"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = GenQA(dev_data_address)\n",
        "test_dataloader = DataLoader(test_data, batch_size=test_batch_size, shuffle=False, collate_fn=collote_fn)\n",
        "\n",
        "import json\n",
        "\n",
        "model.load_state_dict(torch.load('epoch_1_valid_bleu_53.38_model_weights.bin'))\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print('evaluating on test set...')\n",
        "    sources, preds, labels = [], [], []\n",
        "    for batch_data in tqdm(test_dataloader):\n",
        "        batch_data = batch_data.to(device)\n",
        "        generated_tokens = model.generate(\n",
        "            batch_data[\"input_ids\"],\n",
        "            attention_mask=batch_data[\"attention_mask\"],\n",
        "            max_length=max_length,\n",
        "        ).cpu().numpy()\n",
        "        label_tokens = batch_data[\"labels\"].cpu().numpy()\n",
        "\n",
        "        decoded_sources = tokenizer.batch_decode(\n",
        "            batch_data[\"input_ids\"].cpu().numpy(),\n",
        "            skip_special_tokens=True,\n",
        "            use_source_tokenizer=True\n",
        "        )\n",
        "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "        print(\"input:\", decoded_sources)\n",
        "        print(\"output:\", decoded_preds)\n",
        "        label_tokens = np.where(label_tokens != -100, label_tokens, tokenizer.pad_token_id)\n",
        "        decoded_labels = tokenizer.batch_decode(label_tokens, skip_special_tokens=True)\n",
        "        print(\"labels:\", decoded_labels)\n",
        "\n",
        "        sources += [source.strip() for source in decoded_sources]\n",
        "        preds += [pred.strip() for pred in decoded_preds]\n",
        "        labels += [[label.strip()] for label in decoded_labels]\n",
        "    bleu_score = bleu.corpus_score(preds, labels).score\n",
        "    print(f\"Test BLEU: {bleu_score:>0.2f}\\n\")\n",
        "    results = []\n",
        "    print('saving predicted results...')\n",
        "    for source, pred, label in zip(sources, preds, labels):\n",
        "        results.append({\n",
        "            \"sentence\": source,\n",
        "            \"prediction\": pred,\n",
        "            \"translation\": label[0]\n",
        "        })\n",
        "    with open('test_data_pred.json', 'wt', encoding='utf-8') as f:\n",
        "        for exapmle_result in results:\n",
        "            f.write(json.dumps(exapmle_result, ensure_ascii=False) + '\\n')"
      ],
      "metadata": {
        "id": "-HT0VGC_AVML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3TOFYQRKYjP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}